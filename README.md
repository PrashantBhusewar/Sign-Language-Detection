# Sign-Language-Detection

## *Problem statement*

Sign languages are languages that use the visual-manual modality to convey meaning, instead of just spoken words. Sign languages are expressed through manual articulation in combination with non-manual markers. Sign languages are full-fledged natural languages with their grammar and lexicon.

Communication is the act of sharing or exchanging information, ideas or feelings. To establish communication between two people, both of them are required to have knowledge and understanding of a common language. But in the case of deaf and dumb people, the means of communication are different. Deaf is the inability to hear and dumb is the inability to speak. They communicate using sign language among themselves and with normal people but normal people do not take seriously the importance of sign language. Not everyone possesses the knowledge and understanding of sign language which makes communication difficult between a normal person and a deaf and dumb person.


## *Solution Proposed*

One can build a model based on deep-learning Computer Vision to overcome this barrier. A model can be trained to recognize different gestures of sign language and translate them into English. This will help a lot of people in communicating and conversing with deaf and dumb people. This is an object detection solution which can detect various sign language activity.


## *Scope of Application*

A sign Language recognition system could be used at reception desks or during video conferences to allow signing people to speak with people who don't know Sign Language.


## *Cost Involved*
- Model Training Cost
- Model Storing Cost
- Deployment Cost

## *Tech Stack Used*
- Python
- Flask
- Computer Vision
- Docker
- Yolo v5


## *Infrastructure required*
- AWS S3
- EC2
- GitHub Actions
